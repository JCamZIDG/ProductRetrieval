{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18167fa",
   "metadata": {},
   "source": [
    "# Product Retrieval System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ff614",
   "metadata": {},
   "source": [
    "El objetivo es medir qué tan bien el modelo recupera los productos más relevantes \n",
    "para cada consulta de usuario (`query`), basándonos en los datos del dataset WANDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b781e47-2986-4c1d-b1f6-28361312aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f92e6",
   "metadata": {},
   "source": [
    "## Óptimización de TF-IDF\n",
    "\n",
    "Esta área abarca las opciones de mejora que se tienen para el modelo original de TF-IDF que poseemos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a674a46",
   "metadata": {},
   "source": [
    "### Lemmatizar los textos\n",
    "\n",
    "En este apartado vamos a aplicar una lematización, dado que hasta ahora hemos estado comparando las palabras sin pensar en la raíz de la que podrían provenir algunas por lo que se realizará la prueba lematizando las palabras y ver su efectividad en la calidad de los resultados.\n",
    "\n",
    "Para este caso vamos a usar spacy para lograr nuestro cometido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ac49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    # only get lema of alphabetic non-stopwords\n",
    "    return [token.lemma_ for token in doc \n",
    "            if not token.is_stop and token.is_alpha]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2384d13-941a-4c49-b903-68c5cf55ac15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'WANDS'...\n"
     ]
    }
   ],
   "source": [
    "#clone the git repo that contains the data and additional information about the dataset\n",
    "!git clone https://github.com/wayfair/WANDS.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928fa52",
   "metadata": {},
   "source": [
    "### Aplicando Parámetros Óptimos\n",
    "\n",
    "Más adelante se explicará como se realizó la búsqueda de los parámetros óptimos con los que se ejecutó la celda posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42485468-77e2-4fc3-9a70-319a70603472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define functions for product search using Tf-IDF\n",
    "def calculate_tfidf(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate the TF-IDF for combined product name and description.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): DataFrame with product_id, and other product information.\n",
    "\n",
    "    Returns:\n",
    "    TfidfVectorizer, csr_matrix: TF-IDF vectorizer and TF-IDF matrix.\n",
    "    \"\"\"\n",
    "    # Combine product name and description to vectorize\n",
    "    # NOTE: Please feel free to use any combination of columns available, some columns may contain NULL values\n",
    "    combined_text = dataframe['product_name'] + ' ' + dataframe['product_description']\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=lemma_tokenizer,\n",
    "        sublinear_tf=True,\n",
    "        stop_words='english',\n",
    "    )\n",
    "\n",
    "\n",
    "    # convert combined_text to list of unicode strings\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_text.values.astype('U'))\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def get_top_products(vectorizer, tfidf_matrix, query, top_n=10):\n",
    "    \"\"\"\n",
    "    Get top N products for a given query based on TF-IDF similarity.\n",
    "\n",
    "    Parameters:\n",
    "    vectorizer (TfidfVectorizer): Trained TF-IDF vectorizer.\n",
    "    tfidf_matrix (csr_matrix): TF-IDF matrix for the products.\n",
    "    query (str): Search query.\n",
    "    top_n (int): Number of top products to return.\n",
    "\n",
    "    Returns:\n",
    "    list: List of top N product IDs.\n",
    "    \"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_product_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    return top_product_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd06913-4149-44c7-a876-787316e1b1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define functions for evaluating retrieval performance\n",
    "def map_at_k(true_ids, predicted_ids, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision at K (MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    true_ids (list): List of relevant product IDs.\n",
    "    predicted_ids (list): List of predicted product IDs.\n",
    "    k (int): Number of top elements to consider.\n",
    "             NOTE: IF you wish to change top k, please provide a justification for choosing the new value\n",
    "\n",
    "    Returns:\n",
    "    float: MAP@K score.\n",
    "    \"\"\"\n",
    "    #if either list is empty, return 0\n",
    "    if not len(true_ids) or not len(predicted_ids):\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p_id in enumerate(predicted_ids[:k]):\n",
    "        if p_id in true_ids and p_id not in predicted_ids[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(true_ids), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffb18c",
   "metadata": {},
   "source": [
    "### Nuevas Metricas\n",
    "\n",
    "Hemos seleccionado un conjunto pequeño y representativo de métricas:\n",
    "- **MAP@10 (Exact only)**: métrica objetivo del ejercicio; mide precisión ordenada para coincidencias exactas.\n",
    "- **Weighted MAP@10**: extiende MAP para tener en cuenta coincidencias parciales (Exact=1, Partial=0.X).\n",
    "- **NDCG@10**: métrica estándar para relevancia graduada (útil para comparar cuando hay niveles de relevancia).\n",
    "- **Precision@10 / Recall@10**: métricas intuitivas de calidad y cobertura en los primeros K resultados.\n",
    "\n",
    "En las siguientes celdas ejecutaremos una evaluación comparativa entre el recuperador semántico (FAISS) y la versión con reranking (Cross-Encoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc51ce2-521c-428c-8475-57fbc7145d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def dcg_from_scores(rels):\n",
    "    return sum((2**r - 1) / math.log2(i+2) for i, r in enumerate(rels))\n",
    "\n",
    "def ndcg_at_k_from_relevance_list(relevance_list, k=10):\n",
    "    topk = relevance_list[:k]\n",
    "    dcg = dcg_from_scores(topk)\n",
    "    ideal = sorted(relevance_list, reverse=True)[:k]\n",
    "    idcg = dcg_from_scores(ideal)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def precision_at_k(predicted_ids, relevant_set, k=10):\n",
    "    topk = predicted_ids[:k]\n",
    "    return sum(1 for pid in topk if pid in relevant_set) / k\n",
    "\n",
    "def recall_at_k(predicted_ids, relevant_set, k=10):\n",
    "    topk = predicted_ids[:k]\n",
    "    return sum(1 for pid in topk if pid in relevant_set) / max(1, len(relevant_set))\n",
    "\n",
    "def weighted_map_at_k(relevance_dict, predicted_ids, k=10):\n",
    "    \"\"\"\n",
    "    relevance_dict: {product_id: weight}, weight ∈ [0,1]\n",
    "    predicted_ids: lista de product_id ordenados\n",
    "    \"\"\"\n",
    "    if not relevance_dict or not predicted_ids:\n",
    "        return 0.0\n",
    "\n",
    "    cum_gain = 0.0        \n",
    "    score = 0.0\n",
    "    total_possible = sum(relevance_dict.values())\n",
    "\n",
    "    for i, pid in enumerate(predicted_ids[:k], start=1):\n",
    "        rel = relevance_dict.get(pid, 0.0)\n",
    "        if rel > 0:\n",
    "            cum_gain += rel\n",
    "            score += cum_gain / i\n",
    "\n",
    "    return score / min(total_possible, k) if total_possible > 0 else 0.0\n",
    "\n",
    "def relevance_list_for_predicted_ids(relevance_dict, predicted_ids, default=0.0):\n",
    "    return [relevance_dict.get(pid, default) for pid in predicted_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6f66b3-37d1-48b0-a9f5-fb58003f4cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get search queries\n",
    "query_df = pd.read_csv(\"WANDS/dataset/query.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041c7b89-1985-4dff-86e6-67353c96bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>Massage Chairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>Coffee &amp; Cocktail Tables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>Kids Wall Décor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>Accent Pillows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>Recliners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query               query_class\n",
       "0         0                salon chair            Massage Chairs\n",
       "1         1         smart coffee table  Coffee & Cocktail Tables\n",
       "2         2                   dinosaur           Kids Wall Décor\n",
       "3         3          turquoise pillows            Accent Pillows\n",
       "4         4  chair and a half recliner                 Recliners"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55b7820-00e2-4300-966c-8762d15fd407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get products\n",
    "product_df = pd.read_csv(\"WANDS/dataset/product.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d9c2a5-8c89-41fe-94d4-b0d57a09ca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_class</th>\n",
       "      <th>category hierarchy</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_features</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>solid wood platform bed</td>\n",
       "      <td>Beds</td>\n",
       "      <td>Furniture / Bedroom Furniture / Beds &amp; Headboa...</td>\n",
       "      <td>good , deep sleep can be quite difficult to ha...</td>\n",
       "      <td>overallwidth-sidetoside:64.7|dsprimaryproducts...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>all-clad 7 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>create delicious slow-cooked meals , from tend...</td>\n",
       "      <td>capacityquarts:7|producttype : slow cooker|pro...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>all-clad electrics 6.5 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>prepare home-cooked meals on any schedule with...</td>\n",
       "      <td>features : keep warm setting|capacityquarts:6....</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>all-clad all professional tools pizza cutter</td>\n",
       "      <td>Slicers, Peelers And Graters</td>\n",
       "      <td>Browse By Brand / All-Clad</td>\n",
       "      <td>this original stainless tool was designed to c...</td>\n",
       "      <td>overallwidth-sidetoside:3.5|warrantylength : l...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baldwin prestige alcott passage knob with roun...</td>\n",
       "      <td>Door Knobs</td>\n",
       "      <td>Home Improvement / Doors &amp; Door Hardware / Doo...</td>\n",
       "      <td>the hardware has a rich heritage of delivering...</td>\n",
       "      <td>compatibledoorthickness:1.375 '' |countryofori...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0           0                            solid wood platform bed   \n",
       "1           1                        all-clad 7 qt . slow cooker   \n",
       "2           2            all-clad electrics 6.5 qt . slow cooker   \n",
       "3           3       all-clad all professional tools pizza cutter   \n",
       "4           4  baldwin prestige alcott passage knob with roun...   \n",
       "\n",
       "                  product_class  \\\n",
       "0                          Beds   \n",
       "1                  Slow Cookers   \n",
       "2                  Slow Cookers   \n",
       "3  Slicers, Peelers And Graters   \n",
       "4                    Door Knobs   \n",
       "\n",
       "                                  category hierarchy  \\\n",
       "0  Furniture / Bedroom Furniture / Beds & Headboa...   \n",
       "1  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "2  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "3                         Browse By Brand / All-Clad   \n",
       "4  Home Improvement / Doors & Door Hardware / Doo...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  good , deep sleep can be quite difficult to ha...   \n",
       "1  create delicious slow-cooked meals , from tend...   \n",
       "2  prepare home-cooked meals on any schedule with...   \n",
       "3  this original stainless tool was designed to c...   \n",
       "4  the hardware has a rich heritage of delivering...   \n",
       "\n",
       "                                    product_features  rating_count  \\\n",
       "0  overallwidth-sidetoside:64.7|dsprimaryproducts...          15.0   \n",
       "1  capacityquarts:7|producttype : slow cooker|pro...         100.0   \n",
       "2  features : keep warm setting|capacityquarts:6....         208.0   \n",
       "3  overallwidth-sidetoside:3.5|warrantylength : l...          69.0   \n",
       "4  compatibledoorthickness:1.375 '' |countryofori...          70.0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0             4.5          15.0  \n",
       "1             2.0          98.0  \n",
       "2             3.0         181.0  \n",
       "3             4.5          42.0  \n",
       "4             5.0          42.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d75f84-1152-43c7-b2a0-422267ab2298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get manually labeled groundtruth lables\n",
    "label_df = pd.read_csv(\"WANDS/dataset/label.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b8f157-2049-4cdb-afc4-62e546d59dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25434</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12088</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42931</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2636</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42923</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  query_id  product_id       label\n",
       "0   0         0       25434       Exact\n",
       "1   1         0       12088  Irrelevant\n",
       "2   2         0       42931       Exact\n",
       "3   3         0        2636       Exact\n",
       "4   4         0       42923       Exact"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59768978-5c40-45b0-84a7-d6cc5d469b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#group the labels for each query to use when identifying exact matches\n",
    "grouped_label_df = label_df.groupby('query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1beab6d-1f59-427b-ad9f-1f0c6fcaadcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Trabajo\\My Project\\NewVenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculate TF-IDF\n",
    "vectorizer, tfidf_matrix = calculate_tfidf(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4b8333-b747-4c3e-87bc-4825f934ab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top products for 'armchair':\n",
      "12756 24.41 '' wide tufted polyester armchair\n",
      "4277 26.8 '' wide armchair\n",
      "41270 almaraz 33.7 '' wide leather match armchair\n",
      "6528 waugh 29 '' wide tufted polyester armchair\n",
      "11469 tiemann 30 '' wide polyester armchair\n",
      "42697 donham 25 '' wide armchair\n",
      "23927 catania 30 '' wide polyester armchair\n",
      "1587 akire 26.8 '' wide tufted linen armchair\n",
      "29612 35.5 '' wide velvet armchair\n",
      "1694 ascanio 28.5 '' wide tufted polyester armchair\n"
     ]
    }
   ],
   "source": [
    "#Sanity check code block to see if the search results are relevant\n",
    "#implementing a function to retrieve top K product IDs for a query\n",
    "def get_top_product_ids_for_query(query):\n",
    "    top_product_indices = get_top_products(vectorizer, tfidf_matrix, query, top_n=10)\n",
    "    top_product_ids = product_df.iloc[top_product_indices]['product_id'].tolist()\n",
    "    return top_product_ids\n",
    "\n",
    "#define the test query\n",
    "query = \"armchair\"\n",
    "\n",
    "#obtain top product IDs\n",
    "top_product_ids = get_top_product_ids_for_query(query)\n",
    "\n",
    "print(f\"Top products for '{query}':\")\n",
    "for product_id in top_product_ids:\n",
    "    product = product_df.loc[product_df['product_id'] == product_id]\n",
    "    print(product_id, product['product_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bdeda61-7fb0-4ca6-a9e1-f1789b539f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#implementing a function to retrieve exact match product IDs for a query_id\n",
    "def get_exact_matches_for_query(query_id):\n",
    "    query_group = grouped_label_df.get_group(query_id)\n",
    "    exact_matches = query_group.loc[query_group['label'] == 'Exact']['product_id'].values\n",
    "    return exact_matches\n",
    "\n",
    "#applying the function to obtain top product IDs and adding top K product IDs to the dataframe \n",
    "query_df['top_product_ids'] = query_df['query'].apply(get_top_product_ids_for_query)\n",
    "\n",
    "#adding the list of exact match product_IDs from labels_df\n",
    "query_df['relevant_ids'] = query_df['query_id'].apply(get_exact_matches_for_query)\n",
    "\n",
    "#now assign the map@k score\n",
    "query_df['map@k'] = query_df.apply(lambda x: map_at_k(x['relevant_ids'], x['top_product_ids'], k=10), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed01f293-d87b-4ab0-811a-d39140ed5638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3293063616071429)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the MAP across the entire query set\n",
    "query_df.loc[:, 'map@k'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527c841",
   "metadata": {},
   "source": [
    "Para este punto vemos que ya hemos logrado superar el objetivo inicial que era el pasar del 0.3. Lo cual ya es un gran avance.\n",
    "Confirmando que el uso de la lematización (más algunos parámetros optimizados) nos permiten una mejora inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c58cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now assign the map@k score\n",
    "query_df['map@10'] = query_df.apply(lambda x: map_at_k(x['relevant_ids'], x['top_product_ids'], k=10), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fab21e",
   "metadata": {},
   "source": [
    "### Búsqueda de parámetros óptimos \n",
    "\n",
    "Se probaron distintas combinaciones de parámetros del modelo buscando la combinación óptima.\n",
    "Se descartó el uso de modificar min_df, max_df y ngram_range. Quedando solo stop_words y sublinear_tf los parámetros los que ofrecieron una mejora considerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Trabajo\\My Project\\NewVenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba {'tokenizer': <function lemma_tokenizer at 0x000001B8E89DCAF0>, 'ngram_range': (1, 1), 'min_df': 1, 'max_df': 1.0, 'sublinear_tf': True, 'stop_words': 'english'} → MAP@10=0.3293 (217.5s)\n",
      "                                          tokenizer ngram_range  min_df  \\\n",
      "0  <function lemma_tokenizer at 0x000001B8E89DCAF0>      (1, 1)       1   \n",
      "\n",
      "   max_df  sublinear_tf stop_words    map@10      time_s  \n",
      "0     1.0          True    english  0.329306  217.491477  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def evaluate_vectorizer(params, product_df, query_df):\n",
    "    \"\"\"\n",
    "    Crea TF-IDF con params, recupera top-10 y devuelve MAP@10 medio.\n",
    "    params: dict con claves de TfidfVectorizer\n",
    "    \"\"\"\n",
    "    # 1. Vectorizar\n",
    "    vectorizer = TfidfVectorizer(**params)\n",
    "    tfidf_matrix = vectorizer.fit_transform(\n",
    "        (product_df['product_name'] + ' ' + product_df['product_description'])\n",
    "        .values.astype('U')\n",
    "    )\n",
    "    # 2. Recuperación + evaluación\n",
    "    query_df = query_df.copy()\n",
    "    query_df['top_ids'] = query_df['query'].apply(\n",
    "        lambda q: get_top_products(vectorizer, tfidf_matrix, q, top_n=10)\n",
    "    )\n",
    "    query_df['relevant_ids'] = query_df['query_id'].apply(get_exact_matches_for_query)\n",
    "    query_df['map@10'] = query_df.apply(lambda r: map_at_k(r['relevant_ids'], r['top_ids'], k=10), axis=1)\n",
    "    return query_df['map@10'].mean()\n",
    "\n",
    "# Definir espacio de búsqueda\n",
    "param_grid = {\n",
    "    'tokenizer': [lemma_tokenizer],\n",
    "    'ngram_range': [(1,1)],\n",
    "    'min_df': [1],\n",
    "    'max_df': [1.0],\n",
    "    'sublinear_tf': [True],\n",
    "    'stop_words': ['english']\n",
    "}\n",
    "\n",
    "# Generar combinaciones\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "results = []\n",
    "for params in combinations:\n",
    "    start = time.time()\n",
    "    score = evaluate_vectorizer(params, product_df, query_df)\n",
    "    duration = time.time() - start\n",
    "    results.append({\n",
    "        **params,\n",
    "        'map@10': score,\n",
    "        'time_s': duration\n",
    "    })\n",
    "    print(f\"Proba {params} → MAP@10={score:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values('map@10', ascending=False)\n",
    "print(res_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69f524c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>map@10</th>\n",
       "      <th>time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;function lemma_tokenizer at 0x000001B8E89DCAF0&gt;</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>english</td>\n",
       "      <td>0.329306</td>\n",
       "      <td>217.491477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tokenizer ngram_range  min_df  \\\n",
       "0  <function lemma_tokenizer at 0x000001B8E89DCAF0>      (1, 1)       1   \n",
       "\n",
       "   max_df  sublinear_tf stop_words    map@10      time_s  \n",
       "0     1.0          True    english  0.329306  217.491477  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6ae7f",
   "metadata": {},
   "source": [
    "## Relevancia Parcial\n",
    "\n",
    "Una vez optimizado el modelo TF-IDF, se buscó modificar la métrica de evaluación para que no castigara tanto sin tomar en cuenta los valores \"parciales\", se mantuvo con el valor de 0.5 dado que realmente no poseía el conocimiento suficiente para determinar cual podría ser la ponderación más óptima de los productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef9f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a function to retrieve exact match product IDs for a query_id\n",
    "def get_partial_matches_for_query(query_id):\n",
    "    query_group = grouped_label_df.get_group(query_id)\n",
    "    exact_matches = query_group.loc[query_group['label'] == 'Partial']['product_id'].values\n",
    "    return exact_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d032c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance_scores(query_id, exact_w=1.0, partial_w=0.5):\n",
    "    exact = set(get_exact_matches_for_query(query_id))\n",
    "    partial = set(get_partial_matches_for_query(query_id))\n",
    "    # id → peso de relevancia\n",
    "    return {pid: exact_w for pid in exact} | {pid: partial_w for pid in partial}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eca7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.48919072102665856)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df['relevance_dict'] = query_df['query_id'].apply(get_relevance_scores)\n",
    "\n",
    "query_df['map@10_weighted'] = query_df.apply(\n",
    "    lambda row: weighted_map_at_k(row['relevance_dict'], row['top_product_ids'], k=10),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# MAP final\n",
    "query_df['map@10_weighted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16362fa4",
   "metadata": {},
   "source": [
    "Ya con estos valores vemos que el valor se acerca al 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fea9d",
   "metadata": {},
   "source": [
    "## Migración a recuperación semántica con embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcf063",
   "metadata": {},
   "source": [
    "TF-IDF es un buen baseline, pero tiene limitaciones ante sinónimos, cambios de forma y consultas con poca coincidencia léxica. \n",
    "Para mejorar la recuperación (y potencialmente el MAP@10) probamos una etapa de **embeddings semánticos** usando `sentence-transformers` (all-MiniLM-L6-v2), que produce vectores densos capaces de capturar similitud semántica entre consulta y descripción del producto.\n",
    "\n",
    "En esta sección:\n",
    "- Generamos embeddings para `product_name` + `product_description`.\n",
    "- Construimos un índice FAISS para búsqueda rápida por similaridad (producto ↔ consulta).\n",
    "- Compararemos métricas (MAP@10 y weighted MAP@10) con el baseline TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ff045",
   "metadata": {},
   "source": [
    "### ¿Por qué deberíamos probar con embbedings?\n",
    "\n",
    "- **Robustez léxica**: los embeddings representan significado, no sólo coincidencia de palabras; detectan sinónimos y paráfrasis. El tener contexto debería beneficiar los resultados\n",
    "- **Generalización**: consultas cortas o mal escritas aún pueden mapear a descripciones semánticamente cercanas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3483d",
   "metadata": {},
   "source": [
    "### Generación de embeddings\n",
    "\n",
    "Usamos `sentence-transformers/all-MiniLM-L6-v2` por ser ligero y efectivo en tareas de búsqueda semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b34db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Trabajo\\My Project\\NewVenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 672/672 [00:47<00:00, 14.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "combined_text = (\n",
    "    product_df['product_name'].fillna('') + ' ' +\n",
    "    product_df['product_description'].fillna('')\n",
    ").astype(str).tolist()\n",
    "\n",
    "product_embeddings = embedding_model.encode(\n",
    "    combined_text,\n",
    "    convert_to_tensor=True,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b53dd3",
   "metadata": {},
   "source": [
    "### Indexado con FAISS y normalización\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) permite búsquedas de vecindad muy rápidas a escala. \n",
    "Construimos un índice `IndexFlatIP` para producto-embedding con similaridad por producto usando **inner product** sobre vectores L2 normalizados (equivalente a coseno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db613362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "product_embeddings = F.normalize(product_embeddings, p=2, dim=1)\n",
    "\n",
    "embeddings_np = product_embeddings.cpu().numpy().astype('float32')\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings_np.shape[1])\n",
    "index.add(embeddings_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ad58e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "faiss.write_index(index, os.path.join(output_dir, \"faiss.index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97651f",
   "metadata": {},
   "source": [
    "### Funciones de recuperación semántica\n",
    "\n",
    "Definimos helpers:\n",
    "- `get_top_semantic(query, top_k)`: devuelve índices (posiciones en `product_df`) de los top K por similaridad.\n",
    "- `get_top_semantic_ids(query, top_k)`: mapea índices → `product_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_semantic(query, top_k=10):\n",
    "    q_emb = embedding_model.encode([query], convert_to_tensor=True)\n",
    "    q_np = q_emb.cpu().numpy().astype('float32')\n",
    "    faiss.normalize_L2(q_np)\n",
    "    D, I = index.search(q_np, top_k)\n",
    "    return I.flatten().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb9660b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_semantic_ids(query, top_k=10):\n",
    "    idxs = get_top_semantic(query, top_k)\n",
    "    return product_df.iloc[idxs]['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a25b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['top_semantic_ids'] = query_df['query'].apply(get_top_semantic_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b820267",
   "metadata": {},
   "source": [
    "### Comparativa TF-IDF vs Embeddings (semántico)\n",
    "\n",
    "Mostramos MAP@10 y Weighted MAP@10 para comparar ambos enfoques.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdefb7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 TF-IDF     : 0.3293063616071429\n",
      "MAP@10 Semántico : 0.3353198072824809\n"
     ]
    }
   ],
   "source": [
    "query_df['map10_semantic'] = query_df.apply(\n",
    "    lambda row: map_at_k(row['relevant_ids'], row['top_semantic_ids'], k=10),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"MAP@10 TF-IDF     :\", query_df['map@k'].mean())\n",
    "print(\"MAP@10 Semántico :\", query_df['map10_semantic'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24339229",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['map10_semantic_weighted'] = query_df.apply(\n",
    "    lambda row: weighted_map_at_k(row['relevance_dict'], row['top_semantic_ids'], k=10),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c0266f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 TF-IDF  : 0.48919072102665856\n",
      "MAP@10 Semantic: 0.5342082347629222\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP@10 TF-IDF  :\", query_df['map@10_weighted'].mean())\n",
    "print(\"MAP@10 Semantic:\", query_df['map10_semantic_weighted'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b258ce9",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "De esta forma podemos llegar a las siguientes conclusiones:\n",
    "\n",
    "- **Resultado**: El pipeline con `sentence-transformers` + FAISS ha logrado mejorar MAP@10 y Weighted MAP@10. Esto sugiere que la representación densa captura relaciones semánticas que TF-IDF no ve alegando los motivos que mencionamos anteriormente.\n",
    "- **Coste**: Generar embeddings y mantener un índice FAISS requiere más memoria/CPU/GPU y tiempo inicial, pero se compensa con los resultados\n",
    "- **Siguiente paso lógico**: añadir un reranker (Cross-Encoder) y/o un RAG/LLM para justificar o refinar la selección. Además de ello, la evaluación lo sugiere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cecac4",
   "metadata": {},
   "source": [
    "## Reranker (Cross-Encoder) y RAG (GPT4All)\n",
    "\n",
    "Objetivo: afinar la lista candidata (FAISS) con un cross-encoder para mejorar ranking,\n",
    "y usar un LLM local para justificar la elección (RAG). Evaluamos el impacto en MAP@10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fcc67",
   "metadata": {},
   "source": [
    "Primero se implementa la función para evaluar nuevamente el ranking de los índices candidatos otorgados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "from sentence_transformers import CrossEncoder\n",
    "from gpt4all import GPT4All \n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# --- 1) Reranker: carga de cross-encoder (preentrenado MS MARCO) ---\n",
    "\n",
    "cross = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')  \n",
    "\n",
    "def rerank_candidates(query, candidate_indices, top_m=10):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      - ranked_indices: lista de índices (posición en product_df) ordenados desc por score (len <= top_m)\n",
    "      - ranked_scores: lista de scores alineados (floats)\n",
    "    \"\"\"\n",
    "    if len(candidate_indices) == 0:\n",
    "        return [], []\n",
    "\n",
    "    candidate_texts = (\n",
    "        product_df.iloc[candidate_indices]['product_name'].fillna('') + \" - \" +\n",
    "        product_df.iloc[candidate_indices]['product_description'].fillna('')\n",
    "    ).tolist()\n",
    "\n",
    "    # batch predict\n",
    "    inputs = [[query, c] for c in candidate_texts]\n",
    "    scores = cross.predict(inputs)          \n",
    "\n",
    "    \n",
    "    ranked_pos = sorted(range(len(candidate_indices)), key=lambda i: float(scores[i]), reverse=True)\n",
    "    ranked_indices = [candidate_indices[i] for i in ranked_pos[:top_m]]\n",
    "    ranked_scores = [float(scores[i]) for i in ranked_pos[:top_m]]\n",
    "    return ranked_indices, ranked_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc75cee",
   "metadata": {},
   "source": [
    "Se deja preparado el contexto para el LLM a usar. En esta caso se estará usando el de `Meta-Llama-3-8B-Instruct.Q4_0` por el motivo de ser gratuito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) RAG: generación con modelo local gratuito (GPT4All como ejemplo) ---\n",
    "\n",
    "\n",
    "gpt_model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")  \n",
    "\n",
    "def build_context_from_indices(indices, max_chars=3000):\n",
    "    \n",
    "    parts = []\n",
    "    total = 0\n",
    "    for idx in indices:\n",
    "        text = f\"product_id: {product_df.iloc[idx]['product_id']}\\n\" \\\n",
    "               f\"name: {product_df.iloc[idx]['product_name']}\\n\" \\\n",
    "               f\"description: {product_df.iloc[idx]['product_description']}\\n\"\n",
    "        if total + len(text) > max_chars:\n",
    "            break\n",
    "        parts.append(text)\n",
    "        total += len(text)\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297ba37",
   "metadata": {},
   "source": [
    "Finalmente, realizamos la función del RAG para obtener respuesta del LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b233b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query, top_k_retriever=20, rerank_top_m=5):\n",
    "    # 1) Recupera top_k_retriever con FAISS (similiaridad ya indexada en 'index')\n",
    "    q_emb = embedding_model.encode([query], convert_to_tensor=False)  # numpy/1D\n",
    "    q_np = np.array(q_emb).astype('float32')\n",
    "    faiss.normalize_L2(q_np)\n",
    "    D, I = index.search(q_np.reshape(1, -1), top_k_retriever)  # I shape (1, k)\n",
    "    candidate_idxs = I.flatten().tolist()\n",
    "\n",
    "    # 2) Rerank con cross-encoder y quedarnos con rerank_top_m\n",
    "    reranked_idxs, rerank_scores = rerank_candidates(query, candidate_idxs, top_m=rerank_top_m)\n",
    "\n",
    "    # 3) Construir contexto (top passages) y prompt para RAG\n",
    "    context = build_context_from_indices(reranked_idxs, max_chars=3500)\n",
    "    prompt = f\"\"\"\n",
    "        You are a product assistant. Use ONLY the information in the context to answer the user's question.\n",
    "        Return a short JSON with keys: best_product_id, reasons (list of 1-2 short reasons), top_candidates (list of product_id).\n",
    "        If you don't know, say you don't know.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        User question:\n",
    "        {query}\n",
    "\n",
    "        Answer in JSON only.\n",
    "    \"\"\"\n",
    "    # 4) Genera con GPT4All local\n",
    "    with gpt_model.chat_session():\n",
    "        raw = gpt_model.generate(prompt, max_tokens=400)\n",
    "    \n",
    "    import json, re\n",
    "    \n",
    "    json_text = re.search(r'\\{.*\\}', raw, flags=re.DOTALL)\n",
    "    if json_text:\n",
    "        try:\n",
    "            return json.loads(json_text.group(0))\n",
    "        except:\n",
    "            return {\"error\":\"no se pudo parsear JSON del LLM\", \"raw\": raw}\n",
    "    else:\n",
    "        return {\"raw\": raw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "112dc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Evaluación: comparar MAP@10 antes / después del rerank ---\n",
    "def evaluate_rerank_on_queries(query_df, top_k_retriever=50, rerank_top_m=10):\n",
    "    scores = []\n",
    "    for _, row in query_df.iterrows():\n",
    "        q = row['query']\n",
    "        # retrieve top_k_retriever\n",
    "        q_emb = embedding_model.encode([q], convert_to_tensor=False)\n",
    "        q_np = np.array(q_emb).astype('float32')\n",
    "        faiss.normalize_L2(q_np)\n",
    "        D, I = index.search(q_np.reshape(1, -1), top_k_retriever)\n",
    "        candidate_idxs = I.flatten().tolist()\n",
    "        reranked_idxs, _ = rerank_candidates(q, candidate_idxs, top_m=rerank_top_m)\n",
    "        predicted_ids = product_df.iloc[reranked_idxs]['product_id'].tolist()\n",
    "        score = map_at_k(row['relevant_ids'], predicted_ids, k=10)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214da425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 before (semantic): 0.3353198072824809\n",
      "MAP@10 after cross-encoder rerank: 0.44113371040931804\n",
      "{'best_product_id': '40986', 'reasons': ['pet-friendly', 'soft and comfortable'], 'top_candidates': ['40986']}\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP@10 before (semantic):\", query_df['map10_semantic'].mean())\n",
    "new_map = evaluate_rerank_on_queries(query_df, top_k_retriever=50, rerank_top_m=10)\n",
    "print(\"MAP@10 after cross-encoder rerank:\", new_map)\n",
    "\n",
    "print(rag_answer(\"armchair for small living room, pet friendly\", top_k_retriever=30, rerank_top_m=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a47740",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Se observa que haciendo uso del `cross-encoder` hemos obtenido mejores resultados respecto a los obtenidos anteriormente solo con el modelo `semantic`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc505cd",
   "metadata": {},
   "source": [
    "## Evaluación de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "802648d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate_pipeline(query_df, pipeline='semantic', top_k_retriever=50, top_m=10, exact_w=1.0, partial_w=0.5):\n",
    "    \"\"\"Versión ligera: devuelve resumen (MAP, Weighted MAP, NDCG, P@10, R@10).\"\"\"\n",
    "    map_list = []\n",
    "    wmap_list = []\n",
    "    ndcg_list = []\n",
    "    prec_list = []\n",
    "    recall_list = []\n",
    "\n",
    "    for _, row in query_df.iterrows():\n",
    "        q = row['query']\n",
    "        q_emb = embedding_model.encode([q], convert_to_tensor=False)\n",
    "        q_np = np.array(q_emb).astype('float32')\n",
    "        faiss.normalize_L2(q_np)\n",
    "        D, I = index.search(q_np.reshape(1, -1), top_k_retriever)\n",
    "        candidate_idxs = I.flatten().tolist()\n",
    "\n",
    "        if pipeline == 'semantic':\n",
    "            predicted_idxs = candidate_idxs[:top_m]\n",
    "        elif pipeline == 'rerank':\n",
    "            predicted_idxs, _ = rerank_candidates(q, candidate_idxs, top_m=top_m)\n",
    "        else:\n",
    "            raise ValueError(\"pipeline must be 'semantic' or 'rerank'\")\n",
    "\n",
    "        predicted_ids = product_df.iloc[predicted_idxs]['product_id'].tolist()\n",
    "\n",
    "        exact_set = set(get_exact_matches_for_query(row['query_id']))\n",
    "        partial_set = set(get_partial_matches_for_query(row['query_id']))\n",
    "        relevance_dict = {pid: exact_w for pid in exact_set}\n",
    "        for pid in partial_set:\n",
    "            if pid not in relevance_dict:\n",
    "                relevance_dict[pid] = partial_w\n",
    "\n",
    "        map_list.append(map_at_k(list(exact_set), predicted_ids, k=10))\n",
    "        wmap_list.append(weighted_map_at_k(relevance_dict, predicted_ids, k=10))\n",
    "        rel_list = relevance_list_for_predicted_ids(relevance_dict, predicted_ids, default=0.0)\n",
    "        ndcg_list.append(ndcg_at_k_from_relevance_list(rel_list, k=10))\n",
    "        prec_list.append(precision_at_k(predicted_ids, exact_set, k=10))\n",
    "        recall_list.append(recall_at_k(predicted_ids, exact_set, k=10))\n",
    "\n",
    "    summary = {\n",
    "        \"MAP@10 (exact only)\": np.mean(map_list),\n",
    "        \"Weighted MAP@10\": np.mean(wmap_list),\n",
    "        \"NDCG@10 (graded)\": np.mean(ndcg_list),\n",
    "        \"Precision@10\": np.mean(prec_list),\n",
    "        \"Recall@10\": np.mean(recall_list),\n",
    "    }\n",
    "    return summary, np.array(wmap_list), np.array(ndcg_list), np.array(map_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Bootstrap paired difference (CI) para arrays por-query\n",
    "# --------------------\n",
    "def bootstrap_paired_diff(arrA, arrB, n_boot=2000, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    n = len(arrA)\n",
    "    diffs = []\n",
    "    for _ in range(n_boot):\n",
    "        idxs = [rng.randrange(n) for _ in range(n)]\n",
    "        a = np.mean([arrA[i] for i in idxs])\n",
    "        b = np.mean([arrB[i] for i in idxs])\n",
    "        diffs.append(a - b)\n",
    "    diffs = sorted(diffs)\n",
    "    low = diffs[int(0.025 * n_boot)]\n",
    "    high = diffs[int(0.975 * n_boot)]\n",
    "    mean_diff = np.mean(diffs)\n",
    "    return {\"mean_diff\": mean_diff, \"95%_CI\": (low, high)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e466ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando pipeline SEMANTIC (FAISS top-10)...\n",
      "Resultado SEMANTIC (promedios):\n",
      "  MAP@10 (exact only)      : 0.3353\n",
      "  Weighted MAP@10          : 0.5342\n",
      "  NDCG@10 (graded)         : 0.8713\n",
      "  Precision@10             : 0.3223\n",
      "  Recall@10                : 0.1729\n",
      "\n",
      "Evaluando pipeline RERANK (FAISS -> CrossEncoder -> top-10)...\n",
      "Resultado RERANK (promedios):\n",
      "  MAP@10 (exact only)      : 0.4411\n",
      "  Weighted MAP@10          : 0.5971\n",
      "  NDCG@10 (graded)         : 0.8942\n",
      "  Precision@10             : 0.3769\n",
      "  Recall@10                : 0.2213\n",
      "\n",
      "Bootstrap paired (RERANK - SEMANTIC) sobre Weighted MAP@10:\n",
      "  mean difference: 0.062882\n",
      "  95% CI         : (0.048660, 0.077632)\n",
      "\n",
      "Grid search partial_w (Weighted MAP@10) — probando valores: [0.2, 0.4, 0.5, 0.7, 0.9]\n",
      "  partial_w=0.20 -> SEM WMAP=0.4134  |  RER WMAP=0.4887\n",
      "  partial_w=0.40 -> SEM WMAP=0.4933  |  RER WMAP=0.5603\n",
      "  partial_w=0.50 -> SEM WMAP=0.5342  |  RER WMAP=0.5971\n",
      "  partial_w=0.70 -> SEM WMAP=0.6161  |  RER WMAP=0.6709\n",
      "  partial_w=0.90 -> SEM WMAP=0.6980  |  RER WMAP=0.7447\n",
      "\n",
      "Grid results (ordenado por rerank Weighted MAP):\n",
      " partial_w  sem_weighted_map  rer_weighted_map\n",
      "       0.9          0.697966          0.744706\n",
      "       0.7          0.616062          0.670872\n",
      "       0.5          0.534230          0.597132\n",
      "       0.4          0.493346          0.560301\n",
      "       0.2          0.413414          0.488703\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# Ejecutar evaluación: baseline (semantic) y rerank\n",
    "# --------------------\n",
    "\n",
    "TOP_K_RETRIEVER = 50\n",
    "TOP_M = 10\n",
    "EXACT_W = 1.0\n",
    "PARTIAL_W = 0.5   \n",
    "\n",
    "print(\"Evaluando pipeline SEMANTIC (FAISS top-10)...\")\n",
    "sem_res_avg, sem_wmap_arr, sem_ndcg_arr, sem_mapbin_arr = evaluate_pipeline(\n",
    "    query_df,\n",
    "    pipeline='semantic',\n",
    "    top_k_retriever=TOP_K_RETRIEVER,\n",
    "    top_m=TOP_M,\n",
    "    exact_w=EXACT_W,\n",
    "    partial_w=PARTIAL_W\n",
    ")\n",
    "print(\"Resultado SEMANTIC (promedios):\")\n",
    "for k, v in sem_res_avg.items():\n",
    "    print(f\"  {k:25s}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluando pipeline RERANK (FAISS -> CrossEncoder -> top-10)...\")\n",
    "rer_res_avg, rer_wmap_arr, rer_ndcg_arr, rer_mapbin_arr = evaluate_pipeline(\n",
    "    query_df,\n",
    "    pipeline='rerank',\n",
    "    top_k_retriever=TOP_K_RETRIEVER,\n",
    "    top_m=TOP_M,\n",
    "    exact_w=EXACT_W,\n",
    "    partial_w=PARTIAL_W\n",
    ")\n",
    "print(\"Resultado RERANK (promedios):\")\n",
    "for k, v in rer_res_avg.items():\n",
    "    print(f\"  {k:25s}: {v:.4f}\")\n",
    "\n",
    "# --------------------\n",
    "# Bootstrap paired test (Weighted MAP difference)\n",
    "# --------------------\n",
    "bs = bootstrap_paired_diff(rer_wmap_arr, sem_wmap_arr, n_boot=2000, seed=123)\n",
    "print(\"\\nBootstrap paired (RERANK - SEMANTIC) sobre Weighted MAP@10:\")\n",
    "print(f\"  mean difference: {bs['mean_diff']:.6f}\")\n",
    "print(f\"  95% CI         : ({bs['95%_CI'][0]:.6f}, {bs['95%_CI'][1]:.6f})\")\n",
    "\n",
    "# --------------------\n",
    "# Grid-search sencillo para partial_w\n",
    "# --------------------\n",
    "grid = [0.2, 0.4, 0.5, 0.7, 0.9]\n",
    "grid_results = []\n",
    "print(\"\\nGrid search partial_w (Weighted MAP@10) — probando valores:\", grid)\n",
    "for pw in grid:\n",
    "    _, sem_wmap_pw, _, _ = evaluate_pipeline(query_df, pipeline='semantic', top_k_retriever=TOP_K_RETRIEVER, top_m=TOP_M, exact_w=EXACT_W, partial_w=pw)\n",
    "    _, rer_wmap_pw, _, _ = evaluate_pipeline(query_df, pipeline='rerank', top_k_retriever=TOP_K_RETRIEVER, top_m=TOP_M, exact_w=EXACT_W, partial_w=pw)\n",
    "    sem_mean = np.mean(sem_wmap_pw)\n",
    "    rer_mean = np.mean(rer_wmap_pw)\n",
    "    grid_results.append({\"partial_w\": pw, \"sem_weighted_map\": sem_mean, \"rer_weighted_map\": rer_mean})\n",
    "    print(f\"  partial_w={pw:.2f} -> SEM WMAP={sem_mean:.4f}  |  RER WMAP={rer_mean:.4f}\")\n",
    "\n",
    "grid_df = pd.DataFrame(grid_results).sort_values('rer_weighted_map', ascending=False)\n",
    "print(\"\\nGrid results (ordenado por rerank Weighted MAP):\")\n",
    "print(grid_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a70d89",
   "metadata": {},
   "source": [
    "## Resultados finales y conclusión\n",
    "\n",
    "- El pipeline con *FAISS + Cross-Encoder (rerank)* mejora de forma consistente al baseline semántico:\n",
    "  - MAP@10 (Exact) aumentó de **0.3353 → 0.4411**.\n",
    "  - Weighted MAP@10 aumentó de **0.5342 → 0.5971**.\n",
    "  - NDCG@10 subió ligeramente (0.8713 → 0.8942).\n",
    "- El bootstrap paired sobre la diferencia por-query en Weighted MAP@10 (n=2000) muestra una diferencia media **0.0629** con 95% CI = **(0.0487, 0.0776)** — la mejora es estadísticamente significativa.\n",
    "- La grid-search sobre `partial_w` muestra el efecto del peso de las coincidencias `Partial` en la métrica. Se recomienda `partial_w = 0.5` como valor por defecto, pero la elección final depende de prioridades del producto (precisión vs. cobertura).\n",
    "- **Recomendación práctica:** mantener el pipeline FAISS → Cross-Encoder en producción como baseline de búsqueda; añadir una capa RAG/LLM (local o API) únicamente para explicar o justificar la selección cuando sea necesario (ej. fichas de producto destacadas)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
